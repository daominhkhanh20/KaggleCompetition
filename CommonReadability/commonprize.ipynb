{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.7.10","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n","metadata":{"execution":{"iopub.status.busy":"2021-07-16T02:03:03.378051Z","iopub.execute_input":"2021-07-16T02:03:03.379017Z","iopub.status.idle":"2021-07-16T02:03:03.417521Z","shell.execute_reply.started":"2021-07-16T02:03:03.378895Z","shell.execute_reply":"2021-07-16T02:03:03.415731Z"},"trusted":true},"execution_count":1,"outputs":[{"name":"stdout","text":"/kaggle/input/robertalarge/config.json\n/kaggle/input/robertalarge/merges.txt\n/kaggle/input/robertalarge/vocab.json\n/kaggle/input/robertalarge/pytorch_model.bin\n/kaggle/input/robertalarge/modelcard.json\n/kaggle/input/commonlitreadabilityprize/sample_submission.csv\n/kaggle/input/commonlitreadabilityprize/train.csv\n/kaggle/input/commonlitreadabilityprize/test.csv\n/kaggle/input/roberta-base/config.json\n/kaggle/input/roberta-base/merges.txt\n/kaggle/input/roberta-base/vocab.json\n/kaggle/input/roberta-base/pytorch_model.bin\n","output_type":"stream"}]},{"cell_type":"code","source":"import pandas as pd \nimport numpy as np\nimport seaborn as sns \nfrom matplotlib import pyplot as plt \nimport torch \nimport time\nfrom torch import nn\nfrom torch import optim\nfrom torch.utils.data import DataLoader,Dataset,TensorDataset\nfrom transformers import RobertaModel,RobertaTokenizer,AutoTokenizer,AdamW,get_linear_schedule_with_warmup,get_constant_schedule\nfrom collections import defaultdict\nimport os","metadata":{"execution":{"iopub.status.busy":"2021-07-16T02:03:04.417859Z","iopub.execute_input":"2021-07-16T02:03:04.418303Z","iopub.status.idle":"2021-07-16T02:03:13.896248Z","shell.execute_reply.started":"2021-07-16T02:03:04.418271Z","shell.execute_reply":"2021-07-16T02:03:13.895086Z"},"trusted":true},"execution_count":2,"outputs":[]},{"cell_type":"markdown","source":"# Read Data","metadata":{}},{"cell_type":"code","source":"train=pd.read_csv('/kaggle/input/commonlitreadabilityprize/train.csv')\ntest=pd.read_csv('/kaggle/input/commonlitreadabilityprize/test.csv')","metadata":{"execution":{"iopub.status.busy":"2021-07-16T02:03:13.898260Z","iopub.execute_input":"2021-07-16T02:03:13.898727Z","iopub.status.idle":"2021-07-16T02:03:14.053002Z","shell.execute_reply.started":"2021-07-16T02:03:13.898680Z","shell.execute_reply":"2021-07-16T02:03:14.051881Z"},"trusted":true},"execution_count":3,"outputs":[]},{"cell_type":"code","source":"train['length']=train.excerpt.astype(str).apply(lambda x: len(x.split()))\ntest['length']=test.excerpt.astype(str).apply(lambda x: len(x.split()))","metadata":{"execution":{"iopub.status.busy":"2021-07-16T02:03:14.055191Z","iopub.execute_input":"2021-07-16T02:03:14.055550Z","iopub.status.idle":"2021-07-16T02:03:14.109809Z","shell.execute_reply.started":"2021-07-16T02:03:14.055520Z","shell.execute_reply":"2021-07-16T02:03:14.108720Z"},"trusted":true},"execution_count":4,"outputs":[]},{"cell_type":"code","source":"train['number_sentence']=train.excerpt.astype(str).apply(lambda x: len(x.split('.')))\ntest['number_sentence']=test.excerpt.astype(str).apply(lambda x:len(x.split('.')))","metadata":{"execution":{"iopub.status.busy":"2021-07-16T02:03:14.112493Z","iopub.execute_input":"2021-07-16T02:03:14.112976Z","iopub.status.idle":"2021-07-16T02:03:14.126561Z","shell.execute_reply.started":"2021-07-16T02:03:14.112935Z","shell.execute_reply":"2021-07-16T02:03:14.125048Z"},"trusted":true},"execution_count":5,"outputs":[]},{"cell_type":"code","source":"sns.countplot(train.number_sentence)","metadata":{"execution":{"iopub.status.busy":"2021-07-16T02:03:14.128505Z","iopub.execute_input":"2021-07-16T02:03:14.129484Z","iopub.status.idle":"2021-07-16T02:03:14.614736Z","shell.execute_reply.started":"2021-07-16T02:03:14.129251Z","shell.execute_reply":"2021-07-16T02:03:14.613676Z"},"trusted":true},"execution_count":6,"outputs":[{"name":"stderr","text":"/opt/conda/lib/python3.7/site-packages/seaborn/_decorators.py:43: FutureWarning: Pass the following variable as a keyword arg: x. From version 0.12, the only valid positional argument will be `data`, and passing other arguments without an explicit keyword will result in an error or misinterpretation.\n  FutureWarning\n","output_type":"stream"},{"execution_count":6,"output_type":"execute_result","data":{"text/plain":"<AxesSubplot:xlabel='number_sentence', ylabel='count'>"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<Figure size 432x288 with 1 Axes>","image/png":"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\n"},"metadata":{"needs_background":"light"}}]},{"cell_type":"code","source":"train.drop(['url_legal','license','standard_error'],axis=1,inplace=True)\ntest.drop(['url_legal','license'],axis=1,inplace=True)","metadata":{"execution":{"iopub.status.busy":"2021-07-16T02:03:14.616518Z","iopub.execute_input":"2021-07-16T02:03:14.616988Z","iopub.status.idle":"2021-07-16T02:03:14.626925Z","shell.execute_reply.started":"2021-07-16T02:03:14.616945Z","shell.execute_reply":"2021-07-16T02:03:14.625421Z"},"trusted":true},"execution_count":7,"outputs":[]},{"cell_type":"code","source":"train.describe()","metadata":{"execution":{"iopub.status.busy":"2021-07-16T02:03:14.628944Z","iopub.execute_input":"2021-07-16T02:03:14.629532Z","iopub.status.idle":"2021-07-16T02:03:14.671635Z","shell.execute_reply.started":"2021-07-16T02:03:14.629473Z","shell.execute_reply":"2021-07-16T02:03:14.670343Z"},"trusted":true},"execution_count":8,"outputs":[{"execution_count":8,"output_type":"execute_result","data":{"text/plain":"            target       length  number_sentence\ncount  2834.000000  2834.000000      2834.000000\nmean     -0.959319   172.982004        10.034933\nstd       1.033579    16.974390         3.977946\nmin      -3.676268   135.000000         3.000000\n25%      -1.690320   159.000000         7.000000\n50%      -0.912190   175.000000         9.000000\n75%      -0.202540   188.000000        12.000000\nmax       1.711390   205.000000        35.000000","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>target</th>\n      <th>length</th>\n      <th>number_sentence</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>count</th>\n      <td>2834.000000</td>\n      <td>2834.000000</td>\n      <td>2834.000000</td>\n    </tr>\n    <tr>\n      <th>mean</th>\n      <td>-0.959319</td>\n      <td>172.982004</td>\n      <td>10.034933</td>\n    </tr>\n    <tr>\n      <th>std</th>\n      <td>1.033579</td>\n      <td>16.974390</td>\n      <td>3.977946</td>\n    </tr>\n    <tr>\n      <th>min</th>\n      <td>-3.676268</td>\n      <td>135.000000</td>\n      <td>3.000000</td>\n    </tr>\n    <tr>\n      <th>25%</th>\n      <td>-1.690320</td>\n      <td>159.000000</td>\n      <td>7.000000</td>\n    </tr>\n    <tr>\n      <th>50%</th>\n      <td>-0.912190</td>\n      <td>175.000000</td>\n      <td>9.000000</td>\n    </tr>\n    <tr>\n      <th>75%</th>\n      <td>-0.202540</td>\n      <td>188.000000</td>\n      <td>12.000000</td>\n    </tr>\n    <tr>\n      <th>max</th>\n      <td>1.711390</td>\n      <td>205.000000</td>\n      <td>35.000000</td>\n    </tr>\n  </tbody>\n</table>\n</div>"},"metadata":{}}]},{"cell_type":"markdown","source":"# DataLoader","metadata":{}},{"cell_type":"code","source":"def convert_features(excerpt,tokenizer,max_length):\n    excerpt=excerpt.replace('\\n','')\n    token=tokenizer.encode_plus(\n        excerpt,\n        max_length=max_length,\n        padding='max_length',\n        truncation=True,\n        return_attention_mask=True,\n        return_tensors='pt'\n    )\n    return token['input_ids'].squeeze(dim=0),token['attention_mask'].squeeze(dim=0)\n\nclass ColeridgeInitiative(Dataset):\n    def __init__(self,data,tokenizer,max_length=256,is_test=False):\n        self.tokenizer=tokenizer\n        self.max_length=max_length\n        self.data=data\n        self.is_test=is_test\n        self.excerpts=self.data.excerpt.values.tolist()\n        if is_test is False:\n            self.targets=self.data.target.values.tolist()\n    def __len__(self):\n        return len(self.data)\n\n    def __getitem__(self,idx):\n        if self.is_test is False:\n            excerpt,target=self.excerpts[idx],self.targets[idx]\n            input_ids,attention_mask=convert_features(excerpt,tokenizer,self.max_length)\n            return {\n                \"input_ids\":input_ids,\n                \"attention_mask\":attention_mask,\n                \"target\":torch.tensor(target,dtype=torch.float)\n            }\n        else:\n            excerpt=self.excerpts[idx]\n            input_ids,attention_mask=convert_features(excerpt,tokenizer,self.max_length)\n            return {\n                \"input_ids\":input_ids,\n                \"attention_mask\":attention_mask\n            }\n    ","metadata":{"execution":{"iopub.status.busy":"2021-07-16T02:03:14.675024Z","iopub.execute_input":"2021-07-16T02:03:14.675524Z","iopub.status.idle":"2021-07-16T02:03:14.687607Z","shell.execute_reply.started":"2021-07-16T02:03:14.675483Z","shell.execute_reply":"2021-07-16T02:03:14.686329Z"},"trusted":true},"execution_count":9,"outputs":[]},{"cell_type":"code","source":"tokenizer=RobertaTokenizer.from_pretrained('/kaggle/input/roberta-base')","metadata":{"execution":{"iopub.status.busy":"2021-07-16T02:03:14.690066Z","iopub.execute_input":"2021-07-16T02:03:14.691087Z","iopub.status.idle":"2021-07-16T02:03:14.827794Z","shell.execute_reply.started":"2021-07-16T02:03:14.691013Z","shell.execute_reply":"2021-07-16T02:03:14.826697Z"},"trusted":true},"execution_count":10,"outputs":[]},{"cell_type":"code","source":"train_dataset=ColeridgeInitiative(train,tokenizer)\ntest_dataset=ColeridgeInitiative(test,tokenizer,is_test=True)","metadata":{"execution":{"iopub.status.busy":"2021-07-16T02:03:14.830210Z","iopub.execute_input":"2021-07-16T02:03:14.830887Z","iopub.status.idle":"2021-07-16T02:03:14.837754Z","shell.execute_reply.started":"2021-07-16T02:03:14.830828Z","shell.execute_reply":"2021-07-16T02:03:14.836101Z"},"trusted":true},"execution_count":11,"outputs":[]},{"cell_type":"code","source":"batch_size=32\ntrain_loader=DataLoader(dataset=train_dataset,batch_size=batch_size,shuffle=True,pin_memory=True,num_workers=2)\ntest_loader=DataLoader(dataset=test_dataset,batch_size=batch_size,shuffle=False,pin_memory=True,num_workers=2)","metadata":{"execution":{"iopub.status.busy":"2021-07-16T02:03:14.839600Z","iopub.execute_input":"2021-07-16T02:03:14.840287Z","iopub.status.idle":"2021-07-16T02:03:14.851176Z","shell.execute_reply.started":"2021-07-16T02:03:14.840202Z","shell.execute_reply":"2021-07-16T02:03:14.850052Z"},"trusted":true},"execution_count":12,"outputs":[]},{"cell_type":"code","source":"outputs=next(iter(train_loader))\nprint(outputs['input_ids'].size())\nprint(outputs['target'])\nprint(outputs['attention_mask'].size())","metadata":{"execution":{"iopub.status.busy":"2021-07-16T02:03:14.852484Z","iopub.execute_input":"2021-07-16T02:03:14.853391Z","iopub.status.idle":"2021-07-16T02:03:23.096447Z","shell.execute_reply.started":"2021-07-16T02:03:14.853359Z","shell.execute_reply":"2021-07-16T02:03:23.094245Z"},"trusted":true},"execution_count":13,"outputs":[{"name":"stdout","text":"torch.Size([32, 256])\ntensor([-2.1864, -0.5692, -2.3906, -2.0637, -2.2551, -1.3808, -2.1693, -1.1549,\n        -0.4177, -1.6580,  0.0247, -0.3064, -1.8423, -0.9111, -2.3837, -1.5942,\n        -0.9295, -1.7136,  0.0987, -3.2563, -1.5038, -0.9305,  0.4228, -2.9481,\n        -0.1577, -1.8651,  1.1780, -1.5035, -0.5999, -1.3422, -1.4619, -2.1193])\ntorch.Size([32, 256])\n","output_type":"stream"}]},{"cell_type":"markdown","source":"# Model","metadata":{}},{"cell_type":"code","source":"class Model(nn.Module):\n    def __init__(self,is_large=False,drop_prob=0.3):\n        super(Model,self).__init__()\n        if is_large is True:\n            self.bert=RobertaModel.from_pretrained('/kaggle/input/robertalarge',output_hidden_states=True)\n        else:\n            self.bert=RobertaModel.from_pretrained('/kaggle/input/roberta-base',output_hidden_states=True)\n        self.config_model=self.bert.config\n        self.norm=nn.LayerNorm(self.config_model.hidden_size)\n        self.dropout=nn.Dropout(drop_prob)\n        self.linear=nn.Linear(self.config_model.hidden_size,1)\n        self._init_weight(self.norm)\n        self._init_weight(self.linear)\n        self.fine_tune(fine_tune=False)\n\n        self.attention=nn.Sequential(\n            nn.Linear(self.config_model.hidden_size,512),\n            nn.Tanh(),\n            nn.Linear(512,1),\n            nn.Softmax(dim=1)\n        )\n\n    def _init_weight(self,module):\n        if isinstance(module,nn.Linear):\n            module.weight.data.normal_(mean=0,std=self.config_model.initializer_range)\n            if module.bias is not None:\n                module.bias.data.zero_()\n\n        elif isinstance(module,nn.LayerNorm):\n            module.bias.data.zero_()\n            module.weight.data.fill_(1.0)\n\n    def fine_tune(self,fine_tune=False):\n        for child in self.bert.children():\n            for param in child.parameters():\n                param.requires_grad=fine_tune\n\n    def forward(self,input_ids,attention_masks):\n        outputs=self.bert(input_ids,attention_masks)\n        #pooler_output=outputs['pooler_output']\n        last_hidden_state=outputs.hidden_states[-1]\n        weight_attention=self.attention(last_hidden_state)\n        context_vector=torch.sum(weight_attention*last_hidden_state,dim=1)\n        #out=self.norm(context_vector)\n        out=self.linear(self.dropout(context_vector))\n        return out  ","metadata":{"execution":{"iopub.status.busy":"2021-07-16T02:03:23.100513Z","iopub.execute_input":"2021-07-16T02:03:23.100921Z","iopub.status.idle":"2021-07-16T02:03:23.119501Z","shell.execute_reply.started":"2021-07-16T02:03:23.100797Z","shell.execute_reply":"2021-07-16T02:03:23.117827Z"},"trusted":true},"execution_count":14,"outputs":[]},{"cell_type":"code","source":"device=torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\ndef get_model(is_large,epochs=100):\n    model=Model(is_large=is_large).to(device)\n    loss_fn=nn.MSELoss(reduction='mean')\n    optimizer=AdamW(model.parameters(),lr=1e-5)\n    scheduler=get_linear_schedule_with_warmup(\n        optimizer,\n        num_warmup_steps=50,\n        num_training_steps=len(train_loader)*epochs\n    )\n    scheduler_frozen=get_constant_schedule(optimizer)\n    return model,optimizer,scheduler,scheduler_frozen,loss_fn","metadata":{"execution":{"iopub.status.busy":"2021-07-16T02:04:27.118667Z","iopub.execute_input":"2021-07-16T02:04:27.119108Z","iopub.status.idle":"2021-07-16T02:04:27.128565Z","shell.execute_reply.started":"2021-07-16T02:04:27.119076Z","shell.execute_reply":"2021-07-16T02:04:27.126850Z"},"trusted":true},"execution_count":20,"outputs":[]},{"cell_type":"code","source":"def train_model(model,loader,scheduler_model,optimizer,loss_fn):\n    model.train()\n    loss_train=0\n    for idx,features in enumerate(train_loader):\n        input_ids=features['input_ids'].to(device)\n        attention_masks=features['attention_mask'].to(device)\n        targets=features['target'].to(device)\n        out=model(input_ids,attention_masks)\n        loss=torch.sqrt(loss_fn(out.flatten(),targets))\n        optimizer.zero_grad()\n        loss.backward()\n        optimizer.step()\n        scheduler_model.step()\n        loss_train+=loss.item()\n        if idx%50==0:\n            print(idx,end=\" \")\n    \n    print()\n    return loss_train","metadata":{"execution":{"iopub.status.busy":"2021-07-16T02:04:28.814144Z","iopub.execute_input":"2021-07-16T02:04:28.814510Z","iopub.status.idle":"2021-07-16T02:04:28.823928Z","shell.execute_reply.started":"2021-07-16T02:04:28.814479Z","shell.execute_reply":"2021-07-16T02:04:28.822346Z"},"trusted":true},"execution_count":21,"outputs":[]},{"cell_type":"code","source":"def save_checkpoint(model,epoch,scheduler_model):\n    if os.path.exists('/kaggle/Model') is False:\n        os.mkdir('/kaggle/Model')\n    \n    model_state={\n        \"model\":model.state_dict(),\n        \"optimizer\":optimizer.state_dict(),\n        \"scheduler\":scheduler_model.state_dict(),\n        \"loss\":loss_fn,\n        \"epoch\":epoch\n    }\n    model=torch.save(model,\"/kaggle/Model/mode{}.pth\".format(epoch))\n    print(\"Save model done\")","metadata":{"execution":{"iopub.status.busy":"2021-07-16T02:04:29.025423Z","iopub.execute_input":"2021-07-16T02:04:29.025773Z","iopub.status.idle":"2021-07-16T02:04:29.033060Z","shell.execute_reply.started":"2021-07-16T02:04:29.025742Z","shell.execute_reply":"2021-07-16T02:04:29.031327Z"},"trusted":true},"execution_count":22,"outputs":[]},{"cell_type":"code","source":"def __train__(model,scheduler,scheduler_frozen,optimizer,loss_fn,epochs=100):\n    frozen=True\n    for epoch in range(epochs+1):\n        start_time=time.time()\n        if frozen is True:\n            train_loss=train_model(model,train_loader,scheduler_frozen,optimizer,loss_fn)\n            frozen=False\n        else:\n            train_loss=train_model(model,train_loader,scheduler,optimizer,loss_fn)\n        if epoch%2==0:\n            print(f\"Epoch:{epoch}---Loss:{train_loss}---Time:{time.time()-start_time}\")\n    #if epoch>0 and epoch%50==0:\n        #save_checkpoint(model,epoch,scheduler)","metadata":{"execution":{"iopub.status.busy":"2021-07-16T02:04:29.201471Z","iopub.execute_input":"2021-07-16T02:04:29.201806Z","iopub.status.idle":"2021-07-16T02:04:29.211230Z","shell.execute_reply.started":"2021-07-16T02:04:29.201777Z","shell.execute_reply":"2021-07-16T02:04:29.209808Z"},"trusted":true},"execution_count":23,"outputs":[]},{"cell_type":"code","source":"model1,optimizer1,scheduler1,scheduler_frozen1,loss_fn1=get_model(is_large=False,epochs=120)\nmodel2,optimizer2,scheduler2,scheduler_frozen2,loss_fn2=get_model(is_large=True,epochs=100)","metadata":{"execution":{"iopub.status.busy":"2021-07-16T02:04:30.233742Z","iopub.execute_input":"2021-07-16T02:04:30.234210Z","iopub.status.idle":"2021-07-16T02:04:49.959049Z","shell.execute_reply.started":"2021-07-16T02:04:30.234164Z","shell.execute_reply":"2021-07-16T02:04:49.957930Z"},"trusted":true},"execution_count":24,"outputs":[{"name":"stderr","text":"Some weights of the model checkpoint at /kaggle/input/roberta-base were not used when initializing RobertaModel: ['lm_head.dense.bias', 'lm_head.layer_norm.bias', 'lm_head.layer_norm.weight', 'lm_head.dense.weight', 'lm_head.bias', 'lm_head.decoder.weight']\n- This IS expected if you are initializing RobertaModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n- This IS NOT expected if you are initializing RobertaModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\nSome weights of the model checkpoint at /kaggle/input/robertalarge were not used when initializing RobertaModel: ['lm_head.dense.bias', 'lm_head.layer_norm.bias', 'lm_head.layer_norm.weight', 'lm_head.dense.weight', 'lm_head.bias', 'lm_head.decoder.weight']\n- This IS expected if you are initializing RobertaModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n- This IS NOT expected if you are initializing RobertaModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n","output_type":"stream"}]},{"cell_type":"code","source":"__train__(model1,scheduler1,scheduler_frozen1,optimizer1,loss_fn1,epochs=120)","metadata":{"execution":{"iopub.status.busy":"2021-07-16T02:05:02.002204Z","iopub.execute_input":"2021-07-16T02:05:02.002587Z","iopub.status.idle":"2021-07-16T02:53:21.517644Z","shell.execute_reply.started":"2021-07-16T02:05:02.002555Z","shell.execute_reply":"2021-07-16T02:53:21.515798Z"},"trusted":true},"execution_count":25,"outputs":[{"name":"stdout","text":"0 50 \nEpoch:0---Loss:138.09893333911896---Time:25.421906232833862\n0 50 \n0 50 \nEpoch:2---Loss:130.69066202640533---Time:24.11912727355957\n0 50 \n0 50 \nEpoch:4---Loss:113.85121387243271---Time:24.006083726882935\n0 50 \n0 50 \nEpoch:6---Loss:97.117371737957---Time:23.94180202484131\n0 50 \n0 50 \nEpoch:8---Loss:93.50739043951035---Time:23.97847604751587\n0 50 \n0 50 \nEpoch:10---Loss:91.38304835557938---Time:23.90116024017334\n0 50 \n0 50 \nEpoch:12---Loss:90.11770915985107---Time:23.984914302825928\n0 50 \n0 50 \nEpoch:14---Loss:88.22678953409195---Time:23.935205221176147\n0 50 \n0 50 \nEpoch:16---Loss:86.90616619586945---Time:23.87332820892334\n0 50 \n0 50 \nEpoch:18---Loss:85.38600558042526---Time:24.00813603401184\n0 50 \n0 50 \nEpoch:20---Loss:83.06157600879669---Time:23.976161241531372\n0 50 \n0 50 \nEpoch:22---Loss:81.78717827796936---Time:23.912899494171143\n0 50 \n0 50 \nEpoch:24---Loss:80.32548874616623---Time:24.201852560043335\n0 50 \n0 50 \nEpoch:26---Loss:79.43972623348236---Time:23.930581092834473\n0 50 \n0 50 \nEpoch:28---Loss:78.53624886274338---Time:23.94564390182495\n0 50 \n0 50 \nEpoch:30---Loss:77.4726567864418---Time:23.92951226234436\n0 50 \n0 50 \nEpoch:32---Loss:76.24077844619751---Time:23.94220542907715\n0 50 \n0 50 \nEpoch:34---Loss:74.55745708942413---Time:23.94604229927063\n0 50 \n0 50 \nEpoch:36---Loss:73.73759478330612---Time:23.905250310897827\n0 50 \n0 50 \nEpoch:38---Loss:73.40037816762924---Time:23.859660625457764\n0 50 \n0 50 \nEpoch:40---Loss:72.76949816942215---Time:23.917614459991455\n0 50 \n0 50 \nEpoch:42---Loss:71.88976669311523---Time:23.88219690322876\n0 50 \n0 50 \nEpoch:44---Loss:70.95188367366791---Time:23.903716325759888\n0 50 \n0 50 \nEpoch:46---Loss:70.34955471754074---Time:24.477624654769897\n0 50 \n0 50 \nEpoch:48---Loss:69.98720580339432---Time:23.914228439331055\n0 50 \n0 50 \nEpoch:50---Loss:69.05038207769394---Time:23.942824840545654\n0 50 \n0 50 \nEpoch:52---Loss:68.93952238559723---Time:23.932127475738525\n0 50 \n0 50 \nEpoch:54---Loss:68.6515503525734---Time:23.89884662628174\n0 50 \n0 50 \nEpoch:56---Loss:67.58385729789734---Time:23.937209844589233\n0 50 \n0 50 \nEpoch:58---Loss:67.65353035926819---Time:23.923198699951172\n0 50 \n0 50 \nEpoch:60---Loss:67.13964849710464---Time:23.89696741104126\n0 50 \n0 50 \nEpoch:62---Loss:66.65913945436478---Time:24.004533290863037\n0 50 \n0 50 \nEpoch:64---Loss:65.39784210920334---Time:23.837005853652954\n0 50 \n0 50 \nEpoch:66---Loss:66.64926341176033---Time:23.95181441307068\n0 50 \n0 50 \nEpoch:68---Loss:66.37026086449623---Time:23.986016988754272\n0 50 \n0 50 \nEpoch:70---Loss:65.64111310243607---Time:23.918304204940796\n0 50 \n0 50 \nEpoch:72---Loss:66.10349094867706---Time:23.9116952419281\n0 50 \n0 50 \nEpoch:74---Loss:65.30425268411636---Time:23.941959142684937\n0 50 \n0 50 \nEpoch:76---Loss:64.68953669071198---Time:23.91192054748535\n0 50 \n0 50 \nEpoch:78---Loss:64.47188204526901---Time:23.857995986938477\n0 50 \n0 50 \nEpoch:80---Loss:64.00571548938751---Time:24.133888721466064\n0 50 \n0 50 \nEpoch:82---Loss:64.1731145977974---Time:23.90797996520996\n0 50 \n0 50 \nEpoch:84---Loss:63.56942284107208---Time:23.877302169799805\n0 50 \n0 50 \nEpoch:86---Loss:63.62635600566864---Time:23.892622470855713\n0 50 \n0 50 \nEpoch:88---Loss:62.962608218193054---Time:23.91680407524109\n0 50 \n0 50 \nEpoch:90---Loss:64.01156437397003---Time:23.935014486312866\n0 50 \n0 50 \nEpoch:92---Loss:63.15036737918854---Time:23.91106867790222\n0 50 \n0 50 \nEpoch:94---Loss:62.50751820206642---Time:23.941909074783325\n0 50 \n0 50 \nEpoch:96---Loss:62.81135159730911---Time:23.88854455947876\n0 50 \n0 50 \nEpoch:98---Loss:63.546680361032486---Time:23.933645486831665\n0 50 \n0 50 \nEpoch:100---Loss:63.048537731170654---Time:23.887580633163452\n0 50 \n0 50 \nEpoch:102---Loss:63.51434299349785---Time:23.975595951080322\n0 50 \n0 50 \nEpoch:104---Loss:63.51984480023384---Time:23.926055908203125\n0 50 \n0 50 \nEpoch:106---Loss:62.45445358753204---Time:23.951433897018433\n0 50 \n0 50 \nEpoch:108---Loss:62.38949429988861---Time:23.937049865722656\n0 50 \n0 50 \nEpoch:110---Loss:62.66513830423355---Time:23.948512077331543\n0 50 \n0 50 \nEpoch:112---Loss:62.398303508758545---Time:23.92081594467163\n0 50 \n0 50 \nEpoch:114---Loss:62.34873503446579---Time:24.006584882736206\n0 50 \n0 50 \nEpoch:116---Loss:61.864659905433655---Time:23.98387908935547\n0 50 \n0 50 \nEpoch:118---Loss:62.29075759649277---Time:23.919476747512817\n0 50 \n0 50 \nEpoch:120---Loss:63.13341403007507---Time:24.136324644088745\n","output_type":"stream"}]},{"cell_type":"code","source":"__train__(model2,scheduler2,scheduler_frozen2,optimizer2,loss_fn2,epochs=100)","metadata":{"execution":{"iopub.status.busy":"2021-07-16T02:55:18.473947Z","iopub.execute_input":"2021-07-16T02:55:18.474481Z","iopub.status.idle":"2021-07-16T05:01:13.824849Z","shell.execute_reply.started":"2021-07-16T02:55:18.474449Z","shell.execute_reply":"2021-07-16T05:01:13.823391Z"},"trusted":true},"execution_count":27,"outputs":[{"name":"stdout","text":"0 50 \nEpoch:0---Loss:151.8263040781021---Time:74.8418595790863\n0 50 \n0 50 \nEpoch:2---Loss:113.86793875694275---Time:74.76709604263306\n0 50 \n0 50 \nEpoch:4---Loss:92.57349640130997---Time:74.88101077079773\n0 50 \n0 50 \nEpoch:6---Loss:89.29956591129303---Time:74.77918720245361\n0 50 \n0 50 \nEpoch:8---Loss:87.52918219566345---Time:74.77117872238159\n0 50 \n0 50 \nEpoch:10---Loss:85.39869564771652---Time:74.77452492713928\n0 50 \n0 50 \nEpoch:12---Loss:84.51856034994125---Time:74.77562046051025\n0 50 \n0 50 \nEpoch:14---Loss:82.12049788236618---Time:74.78396224975586\n0 50 \n0 50 \nEpoch:16---Loss:81.09508335590363---Time:74.77508044242859\n0 50 \n0 50 \nEpoch:18---Loss:79.31882637739182---Time:74.79730749130249\n0 50 \n0 50 \nEpoch:20---Loss:76.93727195262909---Time:74.81131315231323\n0 50 \n0 50 \nEpoch:22---Loss:75.70340269804001---Time:74.8052077293396\n0 50 \n0 50 \nEpoch:24---Loss:74.46305418014526---Time:74.76715064048767\n0 50 \n0 50 \nEpoch:26---Loss:74.06946837902069---Time:74.79606676101685\n0 50 \n0 50 \nEpoch:28---Loss:71.85747319459915---Time:74.8063714504242\n0 50 \n0 50 \nEpoch:30---Loss:71.77174115180969---Time:74.76776790618896\n0 50 \n0 50 \nEpoch:32---Loss:71.67613804340363---Time:74.81042170524597\n0 50 \n0 50 \nEpoch:34---Loss:69.48575341701508---Time:74.7788360118866\n0 50 \n0 50 \nEpoch:36---Loss:68.63731950521469---Time:74.79097080230713\n0 50 \n0 50 \nEpoch:38---Loss:68.1917153596878---Time:74.8122341632843\n0 50 \n0 50 \nEpoch:40---Loss:67.97383916378021---Time:74.7857027053833\n0 50 \n0 50 \nEpoch:42---Loss:66.97471630573273---Time:74.74036622047424\n0 50 \n0 50 \nEpoch:44---Loss:67.26627987623215---Time:75.27781772613525\n0 50 \n0 50 \nEpoch:46---Loss:66.7951991558075---Time:74.76129865646362\n0 50 \n0 50 \nEpoch:48---Loss:66.12595468759537---Time:74.77073788642883\n0 50 \n0 50 \nEpoch:50---Loss:65.79257488250732---Time:74.789874792099\n0 50 \n0 50 \nEpoch:52---Loss:65.24315762519836---Time:74.79325771331787\n0 50 \n0 50 \nEpoch:54---Loss:65.22232764959335---Time:74.75293731689453\n0 50 \n0 50 \nEpoch:56---Loss:64.10804426670074---Time:74.75961780548096\n0 50 \n0 50 \nEpoch:58---Loss:64.37850078940392---Time:74.8023111820221\n0 50 \n0 50 \nEpoch:60---Loss:64.22791409492493---Time:74.79083299636841\n0 50 \n0 50 \nEpoch:62---Loss:63.437674939632416---Time:75.1226851940155\n0 50 \n0 50 \nEpoch:64---Loss:63.378410041332245---Time:74.79716563224792\n0 50 \n0 50 \nEpoch:66---Loss:62.90094551444054---Time:74.77642893791199\n0 50 \n0 50 \nEpoch:68---Loss:63.49988701939583---Time:74.75581097602844\n0 50 \n0 50 \nEpoch:70---Loss:62.560845136642456---Time:74.77746677398682\n0 50 \n0 50 \nEpoch:72---Loss:62.59026724100113---Time:74.76796555519104\n0 50 \n0 50 \nEpoch:74---Loss:61.62279498577118---Time:74.79348540306091\n0 50 \n0 50 \nEpoch:76---Loss:61.94892141222954---Time:74.76628541946411\n0 50 \n0 50 \nEpoch:78---Loss:61.23653292655945---Time:74.78881192207336\n0 50 \n0 50 \nEpoch:80---Loss:60.921571761369705---Time:74.82517457008362\n0 50 \n0 50 \nEpoch:82---Loss:61.095288544893265---Time:74.79621171951294\n0 50 \n0 50 \nEpoch:84---Loss:61.275512129068375---Time:74.77669882774353\n0 50 \n0 50 \nEpoch:86---Loss:60.8215166926384---Time:74.75598526000977\n0 50 \n0 50 \nEpoch:88---Loss:60.603294640779495---Time:74.7506411075592\n0 50 \n0 50 \nEpoch:90---Loss:60.46223571896553---Time:74.79224061965942\n0 50 \n0 50 \nEpoch:92---Loss:60.75026315450668---Time:74.78366422653198\n0 50 \n0 50 \nEpoch:94---Loss:60.5167641043663---Time:74.79104018211365\n0 50 \n0 50 \nEpoch:96---Loss:60.64496684074402---Time:74.77255058288574\n0 50 \n0 50 \nEpoch:98---Loss:60.77345186471939---Time:74.86873149871826\n0 50 \n0 50 \nEpoch:100---Loss:60.78784844279289---Time:74.7786955833435\n","output_type":"stream"}]},{"cell_type":"code","source":"def make_file_submission(file_name):\n    id=test.id\n    preds=[]\n    model1.eval()\n    model2.eval()\n    for idx,features in enumerate(test_loader):\n        input_ids=features['input_ids'].to(device)\n        attention_mask=features['attention_mask'].to(device)\n        out1=model1(input_ids,attention_mask)\n        out2=model2(input_ids,attention_mask)\n        out1=out1.squeeze(dim=1).cpu().detach().numpy()\n        out2=out2.squeeze(dim=1).cpu().detach().numpy()\n        preds.extend(list((out1+out2)/2))\n    temp={\"id\":id,\"target\":preds}\n    df=pd.DataFrame(temp)\n    print(df.head(5))\n    df.to_csv('/kaggle/working/'+file_name,index=False)","metadata":{"execution":{"iopub.status.busy":"2021-07-16T05:01:48.340776Z","iopub.execute_input":"2021-07-16T05:01:48.341303Z","iopub.status.idle":"2021-07-16T05:01:48.350656Z","shell.execute_reply.started":"2021-07-16T05:01:48.341270Z","shell.execute_reply":"2021-07-16T05:01:48.349259Z"},"trusted":true},"execution_count":28,"outputs":[]},{"cell_type":"code","source":"make_file_submission('submission.csv')","metadata":{"execution":{"iopub.status.busy":"2021-07-16T05:01:51.186878Z","iopub.execute_input":"2021-07-16T05:01:51.187297Z","iopub.status.idle":"2021-07-16T05:01:51.659431Z","shell.execute_reply.started":"2021-07-16T05:01:51.187264Z","shell.execute_reply":"2021-07-16T05:01:51.658272Z"},"trusted":true},"execution_count":29,"outputs":[{"name":"stdout","text":"          id    target\n0  c0f722661 -0.540084\n1  f0953f0a5 -0.302059\n2  0df072751 -0.507102\n3  04caf4e0c -1.303973\n4  0e63f8bea -1.393538\n","output_type":"stream"}]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]}]}